# 移动的ALOHA：学习双手移动的操作与低成本的全身遥操作



![image-20240105104230611](D:\project\learning\aloha01.png)

我们介绍了一个低成本的移动的操作系统，是双手和支持全身遥操作。该系统的成本为3.2万美元，包括板载电源和计算。左图：用户遥控操作从冰箱中获取食物。右图：移动的ALOHA可以通过模仿学习执行复杂的长期任务。

### Abstract

从人类演示中模仿学习[模仿学习（Imitation Learning）介绍 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/25688750)在机器人技术中表现出令人印象深刻的性能。然而，大多数结果集中在桌面操作，缺乏一般有用的任务所需的机动性和灵活性。在这项工作中，我们开发了一个系统，用于模仿移动的操作任务，是双手，需要全身控制。我们首先介绍了移动的ALOHA，一个低成本的和全身的数据采集遥操作系统。它通过一个移动的基地和一个全身遥控操作界面增强了ALOHA系统[104]。使用移动的ALOHA收集的数据，我们然后执行监督行为克隆，并发现与现有的静态ALOHA数据集的协同训练提高了移动的操作任务的性能。每个任务有50个演示，联合训练可以将成功率提高90%，使移动的ALOHA能够自主完成复杂的移动的操作任务，例如炒和服务一片虾，打开一个双门壁柜来存放沉重的烹饪锅，呼叫和进入电梯，以及使用厨房水龙头轻轻冲洗一个用过的平底锅。

### Introduction

从人类提供的演示中模仿学习是开发多面手机器人的一个很有前途的工具，因为它允许人们向机器人教授任意技能。事实上，直接行为克隆可以使机器人学习各种原始的机器人技能，从**移动的机器人的车道跟踪**[67]，**到简单的拾取和放置操作技能[**12，20]，再到更精细的操作技能，如涂比萨酱料或在电池中开槽[18，104]。然而，在现实的日常环境中，许多任务需要移动性和灵巧操纵的全身协调，**而不仅仅是个人的移动性或操纵行为**。例如，考虑图1中将一个沉重的锅放入橱柜中的相对基本的任务。机器人需要首先导航到橱柜，这需要机器人底座的移动性。为了打开橱柜，机器人需要后退，同时牢牢抓住两个门把手，从而激发全身控制。随后，双臂需要抓住锅柄，并一起将锅移入橱柜，强调双手协调的重要性。沿着类似的脉络，烹饪、清洁、家务，甚至简单地使用电梯在办公室导航，都需要移动的操纵，并且通常通过增加双臂的灵活性而变得更容易。在本文中，我们研究的可行性扩展模仿学习的任务，需要全身控制的双手移动的机器人。

**两个主要因素阻碍了模仿学习在双手移动的操作中的广泛应用**。(1)我们缺乏可访问的，即插即用的全身遥控操作硬件。双手移动的操纵器如果购买现成的可能是昂贵的。像PR2和TIAGo这样的机器人的成本**可能超过20万美元**，这使得它们对于典型的研究实验室来说是负担不起的。为了在这些平台上实现远程操作，还需要额外的硬件和校准。例如，PR1使用两个触觉设备进行双手遥控操作和脚踏板控制底座[93]。先前的工作[5]使用**运动捕捉系统将人类运动重新定位到TIAGo机器人**，该机器人仅控制单臂，需要仔细校准。游戏控制器和键盘也用于远程操作Hello Robot Stretch [2]和Fetch robot [1]，但不支持双手或全身远程操作。(2)先前的机器人学习工作还没有表现出高性能的双手移动的操纵复杂的任务。虽然最近的许多工作表明，高度表达的策略类，如扩散模型和transformers可以在细粒度的多模态操作任务上表现良好，但很大程度上还不清楚相同的配方是否适用于移动的操作：由于增加了额外的自由度，臂和基座动作之间的相互作用可能是复杂的，并且基本姿态的小偏差可导致臂的末端执行器姿态的大漂移。总的来说，从硬件和学习的角度来看，先前的工作没有为双手移动的操纵提供实用且令人信服的解决方案。

本文旨在解决将模仿学习应用于双手移动的操作的挑战。在硬件方面，我们提出了移动的ALOHA，一个低成本和全身遥操作系统，用于收集双手移动的操作数据。移动的ALOHA通过将其安装在轮式底座上，扩展了原始ALOHA的功能，即低成本和灵巧的双手操纵装置[104]。然后，用户被物理地拴在系统上，并反向驱动轮子以实现基座移动。这允许在用户双手控制ALOHA的同时独立移动底座。**同时记录机器人的基本速度数据和机械臂操纵数据，形成一个全身遥操作系统**。

在模仿学习方面，我们观察到，简单地连接基础和手臂动作，然后通过直接模仿学习进行训练，可以产生很强的性能。具体来说，我们串联的14自由度关节的ALOHA与移动的基地的线速度和角速度的位置，形成一个16维的动作矢量。这一公式使MobileALOHA能够直接从以前的深度模仿学习算法中受益，几乎不需要改变实现方式。为了进一步提高模仿学习性能，我们受到了最近在不同机器人数据集上进行预训练和协同训练的成功的启发，同时注意到很少有甚至没有可访问的双手移动的操作数据集。因此，我们转向利用来自静态双手数据集的数据，这些数据集更丰富，更容易收集，特别是从[81，104]到RT-X版本[20]的静态ALOHA数据集。它包含825集与任务不相交的移动的ALOHA任务，并有不同的安装位置的两个手臂。尽管在任务和形态的差异，我们观察到几乎所有的移动的操作任务的正迁移，实现等同或更好的性能和数据效率比政策培训只使用移动的ALOHA数据。这一观察结果在不同类别的最先进的模仿学习方法中也是一致的，包括ACT [104]和扩散策略[18]。

本文的主要贡献是学习**复杂的移动的双手操作任务的系统**。该系统的核心是（1）**移动的ALOHA，一种低成本的全身遥操作系统**，以及（2）发现一个简单的协同**训练配方可以有效地学习复杂的移动的操作任务**。我们的远程操作系统能够连续使用多个小时，例如烹饪3道菜，清洁公共浴室和洗衣服。我们的模仿学习结果也适用于各种复杂的任务，**例如打开一个双门壁柜来存放沉重的烹饪锅，呼叫电梯，推椅子，清理溢出的葡萄酒。通过联合训练，我们能够在这些任务上取得超过80%的成功，每个任务只需50个人工演示，与没有联合训练相比，平均绝对提高了34%。**

### Related Work

移动的操纵。许多当前的移动的操纵系统利用基于模型的控制，这涉及将人类的专业知识和见解集成到系统的设计和架构中[9，17，33，52，93]在移动的操作中基于模型的控制的一个著名例子是DARPA机器人挑战赛[56]。.尽管如此，这些系统的开发和维护可能具有挑战性，通常需要大量的团队努力，即使是感知建模中的微小错误也可能导致重大的控制失败[6，51]。最近，基于学习的方法已被应用于移动的操作，减轻了许多繁重的工程。为了解决移动的操作任务的高维状态和动作空间中的探索问题，先前的工作使用预定义的技能原语[86，91，92]，具有分解动作空间的强化学习[38，48，58，94，101]或全身控制目标[36，42，99]。与这些使用动作基元、状态估计器、深度图像或对象边界框的先前工作不同，**模仿学习允许移动的操纵器通过直接将原始RGB观察映射到全身动作来进行端到端学习**，通过需要大量团队努力的大规模测试显示出有希望的结果，并且即使感知建模中的微小错误也会导致重大控制失败[6，51]。最近，基于学习的方法已被应用于移动的操作，减轻了许多繁重的工程。与这些使用动作基元，状态估计器，深度图像或对象边界框的先前工作不同，模仿学习允许移动的操纵器通过直接将原始RGB观察映射到全身动作来进行端到端学习，通过使用室内环境中的真实世界数据[4，12，78]进行大规模训练显示出有希望的结果[39，78]。之前的工作使用通过使用VR界面[76]，动觉教学[100]，经过训练的RL策略[43]，智能手机界面[90]，动作捕捉系统[5]或人类[8]收集的专家演示。先前的工作还通过使用人类运动捕捉套装[19，22，23，26]，外骨骼[32，45，72，75]，用于视觉反馈的VR耳机[15，53，65，87]和触觉反馈设备[14，66]来开发人形遥控操作。Purushottam等人开发了一种附着于力板的外骨骼套装，**用于轮式人形机器人的全身远程操作。然而，没有低成本的解决方案来收集用于双手移动的操纵的全身专家演示。我们提出了移动的ALOHA这个问题。它适用于长达一小时的远程操作，并且不需要FPV护目镜来从机器人的自我中心相机或触觉设备流回视频**。

机器人的模仿学习。模仿学习使机器人能够从专家演示中学习[67]。行为克隆（BC）是一个简单的版本，将观察映射到动作。BC的增强包括将历史与各种架构[12，47，59，77]，新的训练目标[10，18，35，63，104]，正则化[71]，运动原语[7，44，55，62，64，97]和数据预处理[81]相结合。先前的工作也集中在多任务或少镜头模仿学习，[25，27，30，34，46，50，88，102]，语言条件模仿学习[12，47，82，83]，从游戏数据模仿[21，57，74，89]，使用人类视频[16，24，29，60，69，80，84，96]，并使用特定任务的结构[49，83，103]。扩大这些算法的规模已经导致系统善于推广到新的对象，指令或场景[12，13，28，47，54]。最近，对从不同但相似类型的机器人收集的各种真实世界数据集进行的联合训练在单臂操作[11，20，31，61，98]和导航[79]方面显示出有希望的结果。在这项工作中，我们通过利用现有的静态双手操作数据集，使用双手移动的操作的协同训练管道，并表明我们的协同训练管道提高了所有任务和几种模仿学习方法的移动的操作策略的性能和数据效率**。据我们所知，我们是第一个发现与静态操作数据集进行联合训练可以提高移动的操作策略的性能和数据效率的人。**

### Mobile ALOHA Hardware

我们开发了MobileALOHA，这是一种低成本的移动机械手，可以执行广泛的家庭任务。移动的ALOHA继承了原始ALOHA系统[104]的优点，即低成本、快速、可修复的双手遥控操作设置，同时将其功能扩展到桌面操作之外。具体而言，我们纳入了四个关键的设计考虑因素：

1、移动的：该系统可以以与人类步行相当的速度移动，大约为1.42米/秒。

2.稳定：在操作较重的家用物品时，如锅和橱柜，它是稳定的。

3.全身遥控操作：所有自由度都可以同时遥控操作，包括双臂和移动的底座。

4.Untethered：板载电源和计算。

我们选择AgileX Tracer AGV（“Tracer”）作为移动的基础，以下考虑1和2。Tracer是一款低轮廓、差动驱动的移动的底座，专为仓库物流设计。它可以以1.6米/秒的速度移动，与人类的平均步行速度相似。**最大有效载荷为100 kg，高度为17 mm，**我们可以在离地面较低的位置添加平衡配重，以实现理想的倾翻稳定性。我们发现Tracer在无障碍建筑物中具有足够的可通行性：它可以通过10 mm高的障碍物和8度的斜坡，最小离地间隙为30 mm。在实践中，我们发现它能够更具挑战性的地形，如穿越地板和电梯之间的差距。Tracer在美国的价格**为7，000美元**，比Clearpath等公司的AGV便宜5倍以上，具有类似的速度和有效载荷。

然后，我们试图设计一个全身遥控操作系统上的示踪剂移动的基地和ALOHA武器，**即一个遥控操作系统，允许同时控制的基地和两个武器**（考虑3）。这种设计选择在家庭环境中特别重要**，因为它扩展了机器人的可用工作空间**。考虑打开一个双门橱柜的任务。即使对于人类来说，我们在开门时也会自然地后退，以避免碰撞和尴尬的关节配置。**我们的遥操作系统不应限制这种协调的人体运动，**也不会在收集的数据集中引入不必要的伪影。然而，设计一个全身遥控操作系统可能是具有挑战性的，**因为双手已经被ALOHA的领导者手臂占据。**我们发现将操作员的腰部拴在移动的底座上的设计是最简单直接的解决方案，如图2（左）所示。人类可以反向驱动车轮，这些车轮在扭转时摩擦力非常低。我们在乙烯基地板上测量的滚动阻力约为13N，大多数人都可以接受。将操作者直接连接到移动的操纵器还能够在机器人与物体碰撞时实现粗略的触觉反馈。为了改善人体工程学，拴系点的高度和引导臂的位置都可以独立调节，最高可达30厘米。在自主执行期间，也可以通过松开4个螺钉来拆卸系留结构以及两个引导臂。这减少了移动的操纵器的占地面积和重量，如图2（中间）所示。为了改善人体工程学和扩大工作空间，我们还安装了四个ALOHA手臂都面向前方，而不是原来的ALOHA手臂向内。

为了使我们的移动的操纵器不受束缚（考虑4），我们在底座上放置了一个重14公斤的1.26千瓦时电池。它也可以作为平衡重量，以避免翻倒。数据收集和推理过程中的所有计算都是在一台配备Nvidia 3070 Ti GPU（8 GB VRAM）和Intel i7- 12800 H的消费级笔记本电脑上进行的。它接受来自三个罗技C922 x RGB网络摄像头的流媒体，分辨率为480 x640和50 Hz。两个摄像头安装在跟随机器人的手腕上，第三个面向前方。笔记本电脑还接受本体感受流从所有4个手臂通过USB串行端口，并从示踪剂移动的基地通过CAN总线。我们记录的线性和角速度的移动的基地被用作行动的学习策略。我们还记录了所有4个机器人手臂的关节位置，用作政策观察和行动。我们建议读者参考原始的ALOHA论文[104]以了解有关武器的更多细节。

**考虑到上述设计因素，我们以3.2万美元的预算建造了移动的ALOHA，与Franka Panda等单个工业协作机器人相当。如图2（中）所示，移动的机械手可以相对于地面垂直到达65 cm至200 cm之间，可以延伸超过其底座100 cm，可以提升重量为1.5 kg的物体，并且可以在1.5 m的高度施加100 N的拉力。移动的ALOHA能够执行的一些示例任务包括：**

客房服务：给植物浇水，使用吸尘器，上下洗碗机，从冰箱里拿饮料，开门，使用洗衣机，扔被子，塞枕头，拉上拉链挂夹克，叠裤子，开/关灯，自我充电。

烹饪：鸡蛋打好，大蒜切碎，蔬菜开封，倒入液体，鸡腿煎熟，翻炒，蔬菜焯熟，翻炒，装盘食用。

人机交互：与人类打招呼并握手，打开并递给人类啤酒，帮助人类刮胡子和整理床铺。

我们在图2（右）中包含了Mo bile ALOHA的更多技术规格。除了现成的机器人之外，我们还开源了所有的软件和硬件部件，并提供了详细的教程，涵盖了3D打印、组装和软件安装。教程在项目网站上。[Mobile ALOHA (mobile-aloha.github.io)](https://mobile-aloha.github.io/)

### Co-training with Static ALOHA Data

使用模仿学习来解决现实世界机器人任务的典型方法依赖于使用在特定机器人硬件平台上收集的数据集来执行目标任务。然而，这种直接的方法存在冗长的数据收集过程，其中人类操作员在特定机器人硬件平台上为每个任务从头开始收集演示数据。由于这些数据集中有限的视觉多样性，在这些专门数据集上训练的策略通常对感知扰动（例如干扰物和照明变化）不鲁棒[95]。最近，对从不同但相似类型的机器人收集的各种真实世界数据集进行的联合训练在单臂操作[11，20，31，61]和导航[79]方面显示出有希望的结果。

在这项工作中，我们使用了一个协同训练管道，利用现有的静态ALOHA数据集，以提高模仿学习的性能移动的操作，特别是双手手臂动作。静态ALOHA数据集[81，104]总共有825个演示任务，包括Ziploc密封，拿起叉子，糖果包装，撕纸巾，打开带盖的塑料杯，玩乒乓球，胶带分配，使用咖啡机，铅笔交接，紧固尼龙搭扣电缆，开槽电池和处理螺丝刀。请注意，静态ALOHA数据全部收集在黑色桌面上，两个手臂固定面向彼此。这种设置与移动的ALOHA不同，在ALOHA中，背景随着移动底座而变化，两个手臂平行放置，面向前方。我们不使用任何特殊的数据处理技术的RGB观察或双手动作的静态ALOHA数据，我们的共同训练。

将静态ALOHA数据表示为$D_{static}$，将 MOBILE ALOHA数据集表示为$D^{m}_{mobile}$。双手动作表示为目标关节位置$a_{\mathrm{arms}} \in \mathbb{R}^{14}$，其中包括两个连续的夹持器动作，基本动作表示为目标基本线速度和角速度$a_{\text {base }} \in \mathbb{R}^{2}$。任务m的移动的操纵策略$\pi^{m}$的训练目标是:
$$
\begin{array}{l}
\mathbb{E}_{\left(o^{i}, a_{\text {arms }}^{i}, a_{\text {base }}^{i}\right) \sim D_{\text {mobile }}^{m}}\left[L\left(a_{\text {arms }}^{i}, a_{\text {base }}^{i}, \pi^{m}\left(o^{i}\right)\right)\right]+ \\
\mathbb{E}_{\left(o^{i}, a_{\text {arms }}^{i}\right) \sim D_{\text {static }}}\left[L\left(a_{\text {arms }}^{i},[0,0], \pi^{m}\left(o^{i}\right)\right)\right],
\end{array}
$$
其中，$o^i$是由两个腕部相机数据、安装在手臂之间的一个以自我为中心的顶部相机数据以及手臂的关节角度数据组成的观测数据，并且L是模仿学习的损失函数。

我们以相等的概率从静态ALOHA数据Dstatic和移动的ALOHA数据Dm移动的采样。我们将批量大小设置为16。由于静态ALOHA数据点没有移动的基本动作，我们对动作标签进行零填充，因此来自两个数据集的动作具有相同的维度。我们还忽略了静态ALOHA数据中的前置摄像头，因此两个数据集都有3个摄像头。我们仅基于移动的ALOHA数据集Dm移动的的统计数据来规范化每个动作。在我们的实验中，我们将联合收割机这种联合训练方法与多种基本模仿学习方法相结合，包括ACT [104]，扩散策略[18]和VINN [63]。

### TASKS

我们选择了7个任务，涵盖了可能出现在现实应用程序中的各种功能，对象和交互。我们在图3中对它们进行了说明。对于Wipe Wine，机器人需要清理桌子上溢出的葡萄酒。这项任务需要灵活性和双手灵巧性。具体来说，机器人需要首先导航到水龙头并拿起毛巾，然后导航回到桌子。一只手举起酒杯，另一只手需要用毛巾擦拭桌子和杯底。这个任务是不可能的静态ALOHA，并将采取更多的时间为单臂移动的机器人来完成。

对于煮虾，机器人在盛入碗中之前，会在两面煎一片生虾。移动性和双手灵巧性对于这项任务也是必要的：机器人需要从炉子移动到厨房岛，以及用刮刀翻转虾，而另一只手臂倾斜平底锅。由于翻转半熟虾的复杂动力学，这项任务需要比擦拭葡萄酒更高的精度。由于虾可能会稍微粘在锅上，机器人很难用刮刀到达虾下面并精确地将其翻转。

对于冲洗锅，机器人拿起一个脏锅，在水龙头下冲洗，然后把它放在干燥架上。除了前两项任务中的挑战外，打开水龙头也是一个很难理解的挑战。旋钮由闪亮的不锈钢制成，尺寸很小：长约4厘米，直径约0.7厘米。由于基础运动引入的随机性，手臂需要通过“视觉伺服”来主动补偿闪亮旋钮的误差。厘米级的误差可能导致任务失败。

对于使用橱柜，机器人拿起一个沉重的锅，并将其放置在一个双门橱柜内。虽然看起来这是一项不需要移动底座的任务，但机器人实际上需要来回移动四次才能完成这项任务。例如，当打开柜门时，双臂需要抓住把手，同时底座向后移动。这是必要的，以避免碰撞的门，并有两个手臂在其工作空间。像这样的机动也强调了全身遥控操作和控制的重要性：如果手臂和基座控制是分开的，机器人将无法快速流畅地打开两扇门。值得注意的是，在我们的实验中最重的锅重1.4公斤，超过了单臂的有效载荷限制750克，而在两个手臂的组合有效载荷。

对于呼叫电梯，机器人需要通过按下按钮进入电梯。在这项任务中，我们强调长时间导航，大随机化和精确的全身控制。机器人从距离电梯约15米处开始，随机穿过10米宽的大厅。要按下电梯按钮，机器人需要绕过一个柱子，并精确地停在按钮旁边。按下尺寸为2cm×2cm的按钮需要精确度，因为按下外围设备或按得太轻不会激活电梯。机器人还需要快速精确地转弯才能进入电梯门：机器人最宽的部分与门之间只有30厘米的间隙。

对于Push Chairs，机器人需要在长桌子前推5把椅子。这项任务强调了移动的机械手的强度：它需要通过协调的手臂和底座运动来克服5公斤椅子与地面之间的摩擦力。为了使这项任务更具挑战性，我们只收集前3把椅子的数据，并对机器人进行压力测试，以推断第4和第5把椅子。

对于High Five，我们在附录A.1中提供了插图。机器人需要绕着厨房岛走，每当有人从前面接近它时，停止移动并与人类击掌。在击掌之后，机器人应该继续移动，只有当人类离开它的路径时。我们收集穿着不同衣服的数据，并评估训练过的关于看不见的人和看不见的服装的策略。虽然这项任务不需要太高的精度，但它突出了移动的ALOHA在研究人机交互方面的潜力。

我们要强调的是，对于上面提到的所有任务，开环重放对象恢复到相同配置的演示将实现零整个任务的成功。成功完成任务需要学习的策略做出闭环反应并纠正这些错误。我们认为开环重放过程中的误差来源是移动的基站的速度控制。作为一个例子，我们观察到> 10厘米的误差时，平均重播的基本行动为180度转弯半径为1米。我们在附录A.4中提供了有关该实验的更多细节。

### Experiments

我们的目标是回答我们实验中的两个核心问题。

(1)移动的ALOHA能否通过协同训练和少量移动的操作数据获得复杂的移动的操作技能？

(2)移动的ALOHA可以使用不同类型的模仿学习方法吗？包括ACT [104]，扩散策略[18]和基于检索的VINN [63]？我们在现实世界中进行了大量的实验来研究这些问题。

作为预备，我们将研究的所有方法都使用“动作分块”[104]，其中策略预测未来的一系列动作，而不是每个时间步的一个动作。它已经是ACT和扩散策略方法的一部分，并且很容易添加到VINN中。我们发现，动作组块是至关重要的操纵，提高连贯性的生成轨迹，减少延迟从每一步的政策推断。动作分块还为移动的ALOHA提供了一个独特的优势：更灵活地处理硬件不同部分的延迟l。我们观察到我们的移动的基地的目标和实际速度之间的延迟，而位置控制的手臂的延迟要小得多。考虑到移动的基座的d步延迟，我们的机器人执行长度为k的动作块的前k-d个手臂动作和最后k-d个基座动作。



![image-20240116161911538](D:\project\learning\aloha02.png)

全身遥控：直观地控制移动底座和ALOHA的双手手臂，就像操纵木偶一样，轻松录制演示。

连续使用多个小时：进行长时间训练，处理复杂的任务，例如做饭或清洁整个房间。

低成本、可访问的硬件：Mobile ALOHA 利用经过验证的 ALOHA 系统和廉价的移动底座，使其成为研究人员经济实惠且实用的选择。