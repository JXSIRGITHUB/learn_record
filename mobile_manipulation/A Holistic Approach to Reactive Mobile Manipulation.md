# A Holistic Approach to Reactive Mobile Manipulation

反应式移动的操纵的整体方法

摘要：我们提出了一个可分配任务的反应移动的操作系统的设计和实现。与相关工作相反，我们将手臂和基座的自由度作为一个整体结构来处理，这大大提高了所产生的运动的速度和流动性。这种方法的核心是一个强大的和反应式的运动控制器，它可以实现所需的末端执行器的姿态，同时避免关节位置和速度限制，并确保移动机械臂在整个轨迹的机动性。这可以支持基于传感器的行为，例如闭环视觉抓取。由于在我们的方法中不涉及规划，机器人永远不会静止地思考下一步该做什么。我们展示了我们的整体运动控制器的多功能性，通过实施一个拾取和放置系统，使用行为树，并证明这项任务的9自由度的移动机械臂。此外，我们提供了一个开源的实现我们的运动控制器的非完整和全向移动的机械手可在jhavl.github.io/holistic。

**index**                                      移动操纵，     运动控制，         运动学，               和 反应控制。

## 1、INTRODUCTION

规划机器人执行任务是机器人技术中的一个长期挑战，大多数系统采用规划和反应的某种组合。规划采用当前和期望的世界状态，并输出机器人轨迹以实现该改变。解决方案是最佳的一些措施，但计划执行开环，因此其成功是严重依赖于所提供的初始世界状态和机器人在遵循计划的准确性。今天的规划系统非常强大，可以处理具有许多自由度和约束的问题，但规划时间可能是一秒或更长时间的一个重要部分。

相反，反应系统在感觉信息上“关闭循环”。这种系统对环境的变化具有高度的响应性和鲁棒性，但通常不处理复杂的约束，并且所产生的行为通常过于简单，不适合大多数现实世界的任务。

规划-反应二分法在很久以前就被确定了[1]，今天的大多数机器人系统都结合了联合收割机规划和反应子系统。例如，通常使用全局和局部规划器架构，并且“局部规划器”提供系统对真实的世界的反应性。

如图1所示，在这篇文章中，我们扩展了我们早期的工作反应控制的机器人机械臂[2]的移动的机械手，包括一个非完整的基础。这提供了在无限大的工作空间中命令末端执行器速度的能力，其中以最大化臂灵活性并允许整个移动的操纵器的优雅和流畅运动的方式在臂和基座之间最佳地划分运动。我们实现整体运动，同时考虑所有程度的自由度内的二次规划。

![image-20240126113904974](image\image-20240126113904974.png)

然而，在反应性行为所能达到的效果和完成一项有用任务所必需的效果之间仍然存在着巨大的差距。任务通常是一系列行为，需要检测行为何时完成，根据世界状态和目标在行为之间切换，以及错误恢复。

为了使我们的反应式系统可执行任务，我们将其与行为树相结合。与状态机等替代方案相比，行为树更容易表达，并且具有固有的错误恢复能力。行为树协调反应子系统的基于传感器的行为，以实现有用的任务。行为树可以被认为是一种脚本语言的形式，仍然需要人类的聪明才智来创建，但在未来，可以由任务级规划器来合成。其结果是一个整体系统，可以执行复杂的任务，同时表现出流畅和连续的运动，而无需暂停规划。

文章主要贡献：

1） 一种将非完整移动的操纵平台合并到整体反应式运动控制框架中的新方法，其示例代码可在jhavl.github.io/holistic上获得

2）使用行为树的闭环移动的抓取器的完全集成

3）在一个9自由度非完整移动的操作平台上进行了反应式控制和验证，并与以前的工作进行了比较。

## 2、RELATED WORK

近年来，人们设计了许多移动的操纵系统。最突出的是，[3]中的工作使用视觉，触觉和本体感受传感器数据来使用PR 2机器人完成拾取和放置任务。从3D数据中分割出可抓取对象和支撑表面，已知对象具有拟合的网格，点云表示未知对象。使用OMPL运动规划器[4]实现抓取姿势，OMPL运动规划器[4]生成7自由度臂的运动以跟随。[5]中的方法将其扩展到紧密耦合视觉和触觉传感器，以实现抓取失败检测。触觉反馈使得在抓握中的一些局部反应能够解释传感器误差或小的抓握目标扰动。类似的方法在[6]、[7]中的英特尔HERB平台上使用。此外，[8]在ARMAR-III机器人上使用类似的方法进行双臂抓取。在每一个这些作品中，机器人的基础是移动到位，然后驱动臂完成抓取。虽然这简化了问题，但任务是以缓慢且不连续的方式完成的，其中运动并不优雅。优雅运动被定义为安全、舒适、快速和直观[9]。具体来说，速度必须是平稳和一致的-而不是停止-开始或不自然。

**每个上述作品使用运动规划，以找到一个最佳的轨迹受所提供的标准。运动规划器可以提供避免碰撞，避免关节限制，以及许多有用的功能**。然而，相关的计算时间限制了它们的开环控制。在[10]的基准测试中，**OMPL库中的运动规划器在0.61 s至1.3 s范围内计算7自由度臂上的轨迹**，在18.7 s至20.3 s范围内计算18自由度PR2机器人上的轨迹。这种先看后动的范例是缓慢的，并且对环境变化和传感器或运动误差不鲁棒。

[2]中的NEO控制器利用桌面机械手的微分运动学来创建运动控制器，该运动控制器可以避免静态和动态障碍物，同时还避免机械手的关节位置和速度限制。该控制器是纯反应性的，是经典的分解速率运动控制[11]的扩展，该运动控制已被重新构建为二次规划优化问题（QP）。NEO的性能被证明与运动规划器在有障碍物的**到达任务中相当-而计算每一步需要9.8毫秒。**反应运动控制的另一种方法是通过势场，在势场中，机器人被关节限制和障碍物排斥，同时被吸引向目标[12]，[13]，并且已经在移动的操纵器上实现[14]。然而，与NEO [2]相比，势场方法表现不佳，并且对于复杂和混乱的环境变得难以处理。在文献[15]中，反应式全身控制在完整的人形平台上实现，使用移动的基座上的速度控制器和机械手的力控制。反应式运动控制器的低延迟允许机器人操作中比基于规划的方法具有更大的通用性，并使闭环视觉抓取等任务成为可能。

非完整移动的基座的反应式控制具有挑战性，因**为它不能通过时不变状态反馈控制器实现任**意的任务空间速度[16]。这可以通过切换控制算法[17]或基于动态的方法[3]来克服**。控制移动的基座的最突出的方法是基于非线性优化的运动规划[18]。**

将各种控制器组合并集成到移动的操纵系统中可能与设计单个组件一样困难[3]。另一种控制机制，黎曼运动策略，融合来自不同运动控制器的输出来驱动机器人[19]。然而，这个概念仅限于运动生成，缺乏协调感知、导航和驱动的能力。一种常见的方法是使用有限状态机（FSM）或类似的架构[5]。近年来，行为树越来越受欢迎，并已被证明对机器人非常有用，其中复杂的任务需要以健壮，可靠和反应的方式完成[20]。行为树提供了FSM的替代方案，并具有可读性，可维护性和可扩展性等几个优点，同时还提供了更高程度的表达能力[21]。行为树的反应性质为反应式运动控制器提供了比FSM更好的匹配，因为机器人目标和状态信息可以基于视觉/机器人反馈快速轻松地更新，而不需要非常复杂和不可读的状态流。此外，这些好处还扩展到可以简单实现并基于视觉/机器人反馈的反应性错误恢复。



## 3、MODELLING A MOBILE MANIPULATOR

移动的操纵器包括具有一个或多个机械臂的移动基座，其中基座是全向的或非完整的。

### A. Two-Wheel Differential Drive Mobile Manipulators

机器人末端执行器的姿态是:
$$
{ }^{0} \mathbf{T}_{e}={ }^{0} \mathbf{T}_{b}(x, y, \theta){ }^{b} \mathbf{T}_{a}{ }^{a} \mathbf{T}_{e}\left(\kappa_{a}, \boldsymbol{q}_{a}\right) \tag{1}
$$
其中{0}是世界参考坐标系，${ }^{0} \mathbf{T}_{b}$移动底盘的相对姿态相对于{b},${ }^{b} \mathbf{T}_{a}$是常数表示底盘和机械臂基座的变换，${ }^{a} \mathbf{T}_{e}$，机械臂正运动学末端坐标系的变换{e},$k_a$机械臂运动学参数，$q_a$机械臂关节角；

**我们的方法是基于微分运动学，我们希望确定基本速度和关节角速率$\dot{q}_a$之间的关系，以及末端执行器的空间速度$v_e$。为了方便，我们引入一个无穷小变换到运动链（1）来表示基本瞬时运动:**
$$
{ }^{0} \mathbf{T}_{e}={ }^{0} \mathbf{T}_{b} \underbrace{{ }^{b} \mathbf{T}_{b^{\prime}}\left(\delta_{\theta}, \delta_{d}\right)}_{\text {base instantaneous }}{ }^{b^{\prime}} \mathbf{T}_{a}{ }^{a} \mathbf{T}_{e}\left(\kappa_{a}, \boldsymbol{q}_{a}\right) \tag{2}
$$
其中$\delta_{\theta}$和$\delta_{d}$**分别是非完整基底的无限小旋转和向前平移**，我们可以把它看作为一个简单的旋转平移机器人，他的虚拟关节坐标为$\boldsymbol{q}_{b} \in \mathbb{R}^{2}$,$\left\|\boldsymbol{q}_{b}\right\| \rightarrow 0$和$\dot{q}_{b,0}=\dot{\delta}_{\theta}$并且$\dot{q}_{b,1}=\dot{\delta}_{d}$。得到的表达式类似于串联连杆机械臂的正运动学，并且使用[22]的方法，可以将微分运动学写成：
$$
{ }^{0} \boldsymbol{\nu}_{e}={ }^{0} \mathbf{J}_{e}(x, y, \theta, \boldsymbol{q})\left(\begin{array}{c}
\dot{\boldsymbol{q}}_{b} \\
\dot{\boldsymbol{q}}_{a}
\end{array}\right)    \tag{3}
$$
其将移动的操纵系统的所有轴的速度映射到末端执行器空间速度，其中$q=(0_2,q_a)^{T}\in \mathbb{R}^{n}$，n为虚拟关节和机械臂关节之和，在世界坐标系中${ }^{0} \mathbf{J}_{e}(.)$表示了整体机械手的雅可比矩阵**。虚拟基关节的速度与车轮角速度相关**;
$$
\dot{q}_{b, 0}=\frac{R}{W}\left(\varpi_{R}-\varpi_{L}\right), \dot{q}_{b, 1}=\frac{R}{2}\left(\varpi_{R}+\varpi_{L}\right) \tag{4}
$$
其中R是车轮半径，$\varpi_{R},\varpi_{L}$,分别表示机器人的左右轮的速度，W是两个车轮之间的距离。

对一些控制行为，在不同坐标系中表示速度是有效的；例如，在基座标$_{}^{b}v_e$或者末端坐标系$_{}^{e}v_{e}$可以类似的推导出对应的雅可比矩阵$_{}^{b}J_e(q)$和$_{}^{e}J_e(q)$。

利用整体机械手雅可比矩阵，我们可以构造一个分解速率运动控制器：
$$
\dot{\boldsymbol{q}}^{*}(t)={ }^{b} \mathbf{J}_{e}(\boldsymbol{q})^{+}{ }^{b} \boldsymbol{\nu}_{e}^{*}(t) \tag{5}
$$
其中$(.)^{+}$表示Moore-Penrose 伪逆，$\dot{q}^{*}$表示移动机械臂末端执行器经历期望的空间速度所需的关节速度，并且$_{}^{b}v^{*}_{e}=(v_x,v_y,v_z,w_x,w_y,w_z)^{T}$,该控制器代表了移动机械臂整体控制的基本形式；

所需关节速度$\dot{q}^{*}$被划分为基本虚拟关节速度$\dot{q}^{*}_{b}$，该基本虚拟关节速度$\dot{q}^{*}_{b}$使用（4）的单向运动学模型被变换为左右轮速度，并且$\dot{q}^{*}_{a}$对应于臂的关节速度。

### B. Omnidirectional Mobile Manipulators

全向机器人可以在平面内瞬时平移和旋转，并且使用上面的虚拟关节方法，我们定义$\boldsymbol{q}_{b}=(\delta_x, \delta_y,\delta_\theta) \in \mathbb{R}^{3}$。



## 4、MOBILE MANIPULATION MOTION CONTROLLER

![image-20240126140427382](D:\project\learning\mobile_manipulation\image\image-20240126140427382.png)

我们扩展了[2]中为桌面机械手设计的NEO运动控制器，以实现对移动的机械手的整体控制。我们在图2中提供了我们方法的高级概述。该控制器输出关节速度$\dot{q}$，其实现期望的末端执行器速度$_{}^{b}v^{*}_{e}$减去松弛向量（期望速度的故意误差）δ，其中松弛分量用于允许控制器更好地最小化成本并满足某些约束。该控制器表示为QP:
$$
\begin{array}{l} 
\min _{x} \quad f_{o}(\boldsymbol{x})=\frac{1}{2} \boldsymbol{x}^{\top} \mathcal{Q} \boldsymbol{x}+\mathcal{C}^{\top} \boldsymbol{x} \\
\text { subject to } \\
\mathcal{J} \boldsymbol{x}={ }^{b} \boldsymbol{\nu}_{e} \\
\mathcal{A} \boldsymbol{x} \leq \mathcal{B} \\
\mathcal{X}^{-} \leq \boldsymbol{x} \leq \mathcal{X}^{+}
\end{array} \tag{6}
$$
其中$x=(q,\delta)^{T}$是决策变量，$\mathcal{Q}$包含关节速度和松弛成本，$\mathcal{C}$包含可操纵性最大化和辅助性能任务，$\mathcal{J}$包含增强机械臂雅可比矩阵，$\mathcal{A}$和$\mathcal{B}$实现关节位置限制，$\mathcal{X}^{+,-}$限制决策变量的最大值和最小值，为了提升NEO [2]从静止到移动的机械手的能力，我们对QP的公式进行了重大修改，我们将在下面详细介绍。

### A. Velocity Control

末端执行器具有空间速度
$$
{ }^{b} \boldsymbol{\nu}_{e}(t)={ }^{b} \boldsymbol{\nu}_{e}^{*}(t)-\boldsymbol{\delta}(t) \in \mathbb{R}^{6} \tag{7}
$$
其中${ }^{b} \boldsymbol{\nu}^{*}_{e}(t)\in \mathbb{R}^{6}$是期**望的末端执行器空间速度**，$\boldsymbol{\delta}(t) \in \mathbb{R}^{6}$是允许末端执行器偏离期望运动以满足不等式约束的松弛速度，这个运动是从等式约束（6）中创建的。
$$
\mathcal{J}=\left(\begin{array}{ll}
{ }^{b} \mathbf{J}_{e}(\boldsymbol{q}) & \mathbf{1}_{6 \times 6}
\end{array}\right) \in \mathbb{R}^{6 \times(n+6)} \tag{8}
$$

$$
\boldsymbol{x}=\left(\begin{array}{c}
\dot{\boldsymbol{q}} \\
\boldsymbol{\delta}
\end{array}\right) \in \mathbb{R}^{(n+6)} \tag{9}
$$

其中I是单位矩阵。

### B. The Objective Function

优化将使目标函数中的x最小化，该目标函数受到等式和不等式约束。（6）中的目标函数寻求最小化关节速度范数，最小化松弛范数，并根据[23]的测量最大化机器人的可操作性。关于可操作性最大化的更多信息可参见[2]、[24]、[25]。目标函数定义为：
$$
\mathcal{Q}=\left(\begin{array}{cc}
\operatorname{diag}\left(\boldsymbol{\lambda}_{q}\right) & \mathbf{0}_{6 \times 6} \\
\mathbf{0}_{n \times n} & \operatorname{diag}\left(\boldsymbol{\lambda}_{\delta}\right)
\end{array}\right) \in \mathbb{R}^{(n+6) \times(n+6)}  \tag{10}
$$

$$
\mathcal{C}=\left(\begin{array}{c}
\hat{\mathbf{J}}_{m}+\boldsymbol{\epsilon} \\
\mathbf{0}_{6 \times 1}
\end{array}\right) \in \mathbb{R}^{(n+6)} \tag{11}
$$

其中$\lambda_q \in \mathbb{R}^{n} $在最小化关节速度范数和最大化可操作性之间的调整，$\lambda_{\delta} \in \mathbb{R}^{n} $调整添加冗余，$\hat{J}_m$是可操作性的雅可比矩阵，$\epsilon$末端执行器角度的基础；

可操作性$\hat{J}_m$： 可操作性量$m(q)$描述了机械臂如何实现任意末端速度，该标准是能够提供2（或3完整的平台）自由度，有助于对末端执行器速度与无限的工作空间。相比之下，臂通常将具有更多的自由度，但工作空间有限。为了保证手臂能够利用额外的自由度在给定的时间提供任意的末端执行器速度，我们使用手臂关节计算可操作性雅可比矩阵：
$$
\hat{\mathbf{J}}_{m}=\left(\begin{array}{ll}
\mathbf{0}_{b}, & \left.\mathbf{J}_{m}^{a}\left(\boldsymbol{q}_{a}\right)\right)
\end{array}\right. \tag{12}
$$
其中$0_b$是零向量，$J^{a}_{m}(q_a)$是对应于臂关节的可操作性雅可比矩阵[2]。

![image-20240129095847203](D:\project\learning\mobile_manipulation\image\image-20240129095847203.png)

基线方向$\theta_{\epsilon}$ :图3表示了基座到末端执行器的角度，$\theta_{\epsilon}$。当$\theta_{\epsilon}$约等于0度时，平台在向前方向上具有无限的可达范围，当接近正负90度时，平台的可达范围仅限于手臂的可达范围。在我们的方法中，末端执行器朝向目标，因此当约等于0度时，达到最大可达范围。成本函数的线性分量使优化器选择关节速度，该关节速度将移动底座朝向末端执行器的方向。如图三所示，这个成本是：
$$
\boldsymbol{\epsilon}=\left(\begin{array}{ll}
-k_{\epsilon} \theta_{\epsilon}, & \mathbf{0}_{n-1}
\end{array}\right) \tag{13}
$$
其中$\theta_{\epsilon}=\operatorname{atan} 2\left({ }^{b} \mathbf{T}_{e_{1,3}},{ }^{b} \mathbf{T}_{e_{0,3}}\right)$和$k_{\epsilon}$是一个增益，用于调整基极重定向的积极程度。

冗余成本$\lambda_{\delta}$:冗余成本决定了优化器输出中冗余向量的大小。较大的值限制了松弛的可能性和相关的收益，而较小的值则可能导致松弛抵消期望的速度，留下较大的稳态误差。我们选择$\lambda_{\delta}=\frac{1}{\|\boldsymbol{e}\|}$ ,其中e是末端执行器和期望的末端姿态之间的欧几里得距离误差，为优化器提供了可以避免操作限制并在轨迹开始时最大化可操作性的自由度，而增加的限制确保末端执行器继续接近目标。

角速度代价$\lambda_q$机器人手臂具有有限的可操作范围和有限的关节范围，因此我们在QP中选择关节速度成本：
$$
\lambda_{q}=\left(\frac{1}{\|\boldsymbol{e}\|_{b}}, \quad k_{a}\right) \tag{14}
$$
其中可变增益应用于移动的基础关节，而常数ka应用于臂关节。这使得优化器在误差e较大时倾向于移动基座自由度，而在误差较小时倾向于臂自由度。

### C. Joint Position Limit Avoidance

关节位置限制避免实现使用速度阻尼器。速度阻尼器将限制机器人的关节速度，以减小或抵消其接近关节极限的速率。请注意，我们不对虚拟基础关节执行关节位置限制避免。关节限位回避速度阻尼器定义为：
$$
\mathcal{A}=\left(\mathbf{1}_{n \times n+6}\right) \in \mathbb{R}^{(n \times n+6)} \tag{15}
$$

$$
\mathcal{B}=\left(\begin{array}{c}
\mathbf{0}_{b} \\
\eta \frac{\rho_{0}-\rho_{s}}{\rho_{i}-\rho_{s}} \\
\vdots \\
\eta \frac{\rho_{n}-\rho_{s}}{\rho_{i}-\rho_{s}}
\end{array}\right) \in \mathbb{R}^{n} \tag{16}
$$

其中ρ是到最近接头极限的距离，ρi是操作阻尼器的影响距离，ρs是接头到其极限的最小距离。

### D. Position-Based Servoing

我们使用基于位置的伺服（PBS）计划内的运动控制器。该控制器试图将机器人的末端执行器从其当前姿态驱动到期望姿态。PBS配制为
$$
{ }^{b} \boldsymbol{\nu}_{e}^{*}=\beta \psi\left(\left({ }^{b} \mathbf{T}_{e}\right)^{-1}{ }^{b} \mathbf{T}_{e^{*}}\right) \tag{17}
$$
![image-20240129102717196](D:\project\learning\mobile_manipulation\image\image-20240129102717196.png)

## 5 、EXPERIMENTS

我们首先验证我们的运动控制器，演示如何移动的机械手之间的各种姿势，然后演示我们提出的架构执行移动的拾取和放置行为的任务。

### A. Platform Description

我们使用我们内部开发的移动的操作平台Frankie进行以下实验。Frankie由一个欧姆龙LD-60两轮差速驱动底座和一个7英寸的自由Franka-Panda机械手组成。在实验1和2中，我们还使用了一个Omni-Frankie模型的模拟具有完整的基础（这可以实现使用麦克纳姆轮），表现出整体操作与完整的移动的机械手。Frankie和Omni-Frankie的模型是作为Python机器人编程的一部分提供的[26]。对于真实世界的实验，我们使用英特尔实感D435 RGB-D摄像头连接到末端执行器，用于视觉反馈，以支持视觉抓取。Omron LD-60移动的底座使用内置LiDAR在嵌入式计算机上执行定位和绘图。我们使用来自github.com/qcr/ros_omron_agv的软件包控制平台。Frankie包含Intel i5 NUC和Nvidia Xavier来执行图像处理。



### B. Experiment 1: Holistic Motion Controller Validation

在这个模拟实验中，我们首先展示了我们提出的运动控制器如何响应各种所需的末端执行器姿态。从相同的初始姿势开始，基座和臂必须移动以实现期望的末端执行器姿势

a) 机器人前面4米。

b) 机器人右侧4米处。

c) 机器人后侧4米处。

d) 在机器人前方4m处，目标向前和向左移动6 s，然后向右移动6 s，然后静止。

选择距离4 m是因为其足以要求底座和臂运动。

### C. Experiment 2: Random Reaching Task

在此模拟随机到达任务中，移动的机械手必须到达1000个随机生成的有效且可到达的末端效应器姿势，这些姿势位于{0}的4 m半径内。使用此方法，我们：

a) 在Frankie和OmniFrankie上比较我们的整体控制器与单独的基座和臂规划器（使用OMPL [4]的RRTConnect算法）的成功率，这代表了[3]的方法。

b) 比较Frankie使用我们的整体控制器的成功率，同时调整第四节中介绍的$k_{\epsilon}$。

c) 比较Frankie使用我们的整体控制器的成功率，同时调整第四节中介绍的$\hat{J}_m$。

### D. Experiment 3: Repetitive Pick And Place Task

我们评估我们的方法在现实世界中的重复拾取和放置任务的优点。在这个实验中，移动的机械手必须从一个容器中挑选常见的家用物品，并将它们放在房间对面3米处的桌子上。

为了使我们的系统能够对许多相互竞争的目标和状态进行任务分配和响应，我们使用了行为树。行为树是具有单个根顶点的有向无环图。顶点代表行为，边缘代表控制流。顶点执行由作为激活信号的滴答控制。滴答以定义的频率在树中传播。在接收到一个tick时，如果顶点仍在执行，则返回running，如果目标已实现，则返回success，否则返回failure。这个过程使行为树具有高度的反应性，因为整个树在每个滴答声中都得到处理。行为树的全面描述可以在[20]中找到。

我们已经实现了一个行为树来完成这个拾取-放置任务。我们假设机器人定位在环境的二维地图中，并且该地图中的容器/桌子位置是已知的。我们使用GG-CNN来执行抓取点合成[27]和RealSense D435手眼相机来提供深度图像。GG-CNN消耗深度图像并输出从深度图像可见的最佳抓取姿势。

行为树将首先运行一个分支，该分支从任何错误（关节位置、速度、力限制等遇到的错误）中恢复手臂。并将臂移动到准备姿势并将基座移动到初始姿势。任何未处理的故障都将导致树返回到此分支，在此分支中恢复错误并重新初始化平台。树的第二个分支将在成功时重复。这意味着拾取和放置任务将重复，除非失败。

在第二个分支中，机器人将首先尝试抓取物体。如果需要，抓取器会被打开，然后平台使用我们的整体运动控制器移动到定义的拾取姿势，手持摄像机可以看到装有物体的容器。随后，尝试抓握。在抓取尝试中，整体运动控制器引导机器人朝向GG-CNN输出的抓取姿势。当到所需抓取姿势的距离大于0.25 m时，GG-CNN的输出将持续更新整体运动控制器目标。由于RealSense D-435摄像头的最小感应距离，当抓取姿势距离摄像头0.25米时，抓取姿势就会被锁定。在抓取尝试之后，臂退回到检测到抓取成功的就绪配置。通过完全闭合的夹持器（即，手是空的）或臂遇到错误来检测故障。如果检测到失败，则重复抓取尝试。

在成功抓取后，平台移动到放置物体的位置。上下车地点相隔约3米。然后重复拾取和放置序列。

为了与之前的工作进行比较，我们重复了拾取和放置任务，同时使用运动规划器而不是整体控制器。在此实施中，我们使用内部Omron规划器控制移动的底座，并使用OMPL的RRTConnect运动规划器控制手臂[4]。这模仿了[3]中的机器人控制方法。行为树和视觉堆栈保持不变，只是由于运动规划器的开环性质，我们只使用GG-CNN的第一个输出。

## 6、RESULTS

![image-20240129104116653](D:\project\learning\mobile_manipulation\image\image-20240129104116653.png)

### A. Experiment 1 Results

![image-20240129104322477](D:\project\learning\mobile_manipulation\image\image-20240129104322477.png)

我们使用Swift模拟器[26]在图4中显示了实验1中Frankie的机器人运动，但是我们请读者参考补充视频，该视频显示了机器人运动与基于非整体规划的方法的比较，以及完整Omni-Frankie机器人的运动。我们还在jhavl.github.io/holistic上提供了在Frankie和Omni-Frankie移动的操纵器上运行的运动控制器的代码示例。

如图4所示，移动的操纵器实现了实验设定的所有四个姿势。这些动作分别需要5.42、6.17、6.17和13.12秒完成，对应于图4（a）、（B）、（c）和（e）。使用这种方法，机器人分别花了14.32、16.17和16.45秒完成运动，比整体反应方法慢了两到三倍。请注意，由于计划者的开环性质，实验1d）中没有基于计划的方法，其中目标移动。

图4（a）示出了最简单的运动，并且基部和臂部配合，使得臂部保持良好状态并且不过度伸展。图4（B）显示了一个稍微复杂的运动，因为基座必须与手臂合作旋转和平移才能到达目标。基座与手臂合作旋转，防止手臂接近其关节极限。图4（c）显示了一个非常复杂的任务，需要基座和臂之间的密切合作。基座旋转和平移，以确保臂在运动中不会遇到关节限制。图4（d）显示，我们的控制器可以立即，并顺利地对变化的目标姿态作出反应。值得注意的是，这些运动不是计算轨迹的结果，它是反应式整体运动控制器的紧急行为。图4（e）显示，在所有四个运动中，当使用我们提出的控制器时，机器人手臂始终保持良好状态。

图4（f）示出了使用我们提出的整体控制器时每个运动中的累积末端执行器加加速度，以及基于非整体规划的方法，其中忽略了来自初始机器人运动的加加速度。较低的累积加加速度表示更平滑的整体运动，我们看到，整体的方法产生定量平滑的运动比以前的工作，其中涉及脱节的停止-开始运动。

### B. Experiment 2 Results

![image-20240129104544361](D:\project\learning\mobile_manipulation\image\image-20240129104544361.png)

表一显示，完整和非完整的移动的机械手，我们的整体控制器优于非整体运动规划。整体控制器中的故障是由局部最小值引起的，而运动规划故障是在5秒内未找到解决方案的结果。

![image-20240129104830187](D:\project\learning\mobile_manipulation\image\image-20240129104830187.png)

表II显示了$k_{\epsilon}$（13）对性能的影响。为了使机器人完成后续任务（包括抓取）的能力最大化，重要的是使基座到末端执行器的角度$θ_{\epsilon}$最小化.使$k_{\epsilon}$变大将使$θ_{\epsilon}$最小化，但由于病态臂配置导致局部最小值而导致更多的控制器故障。表II表明，$k_{\epsilon}$ =0.1 - 0.5提供了合适的结果。

![image-20240129104910226](D:\project\learning\mobile_manipulation\image\image-20240129104910226.png)

### C. Experiment 3 Results

我们重复实验3十次，总共有100个物体被拾取和放置。机器人成功地拾取和放置了所有100个物体，进行了113次抓取尝试。当我们使用运动规划方法而不是我们的整体控制器重复执行任务时，我们获得了相同的抓取性能。在该实验中，没有由运动控制或机器人致动引起的故障。视觉管道导致GG-CNN网络中的抓取点不正确，从而导致轻微故障。失败的抓取尝试被行为树捕获，并导致抓取重新尝试。完整的实验3在我们的补充视频中显示。

对于所有机器人应用，任务执行时间是一个重要的性能指标。虽然我们在表IV中测量和报告了我们的运动时间，但我们无法在其他报告类似机器人任务的信件中找到计时结果。例如，在[3]中，机器人从包含多个家用物品的工作台上拾取物体，而在[7]中，机器人从包含单个家用物品的工作台上拾取物体。在[6]中，一个移动的机械手必须从一个不需要底座运动的工作台上拾取和放置杯子。任务和运动要求与我们的任务相同，或者在[6]的情况下更容易，所以比较各种方法的运动时间是很有趣的。最好使用已发表的计时结果，但在没有计时结果的情况下，我们通过分析已发表的补充视频材料对计时结果进行了逆向工程，并在表IV中进行了总结。我们可以鼓励未来的作者在他们的信件中包括时间和距离数据，以鼓励有意义的比较。

使用运动规划器的实验3的定时结果也在规划方法下的表IV中示出。抓取时间定义为抓取运动所花费的时间，这导致物体被抓取（包括重复抓取尝试，如适用），拾取和放置时间定义为抓取时间加上到达放下点和放置物体的时间。基于计划的方法都提供了良好的把握成功率，但需要更长的时间来完成任务。如表IV所示，我们的平均抓取时间比运动规划方法快3倍[3]，而比[7]快6倍。我们的平均拾取和放置时间比运动规划方法快2倍，比[6]快3倍。这些定时与实验1中的定时比较一致。从这些实验结果表明，我们的整体和反应式运动控制器可以显着提高任务执行时间的移动的机械手，同时也是可靠的和强大的任务完成。由此产生的运动是优雅的：直观，平滑和快速[9]，而机器人静止所花费的时间已经完全消除。

## 7、CONCLUSION

在这篇文章中，我们提出了一种新的运动控制器，提供反应和整体控制的非完整和完整的移动的操作平台。我们的实验表明，我们的纯反应和整体的方法执行更快，更有效，更强大的比相关的工作。与行为树相结合，我们的反应式系统变得可执行任务，并能够进行错误恢复，如移动的拾取和放置任务所示，其中运动是平滑的，直观的和快速的。由于行为树的多功能性，我们的行为树可以很容易地修改以执行不同的任务，或者扩展[21]以基于自然语言输入自动生成行为树。在未来，我们希望实现与感知相关的行为，例如对象识别和碰撞检测，这使得更广泛的任务可以解决。此外，通过更多的感知，我们可以将[2]中的反应性碰撞避免纳入整体运动控制器中。我们在jhavl.github.io/holistic上提供了在Frankie和Omni-Frankie移动的操纵器上运行的运动控制器的完整示例。





[MMC2. 基于QP的移动机械臂的整体控制 (dingtalk.com)](https://workspace.dingtalk.com/joTzjhhWHaLAB3S82REvUP)

















